{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with [pytest](https://docs.pytest.org/en/latest/) - part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why to write tests?\n",
    "* Who wants to perform manual testing?\n",
    "* When you fix a bug or add a new feature, tests are a way to verify that you did not break anything on the way\n",
    "* If you have clear requirements, you can have matching test(s) for each requirement\n",
    "* You don't have to be afraid of refactoring\n",
    "* Tests document your implementation - they show other people use cases of your implementation\n",
    "* This list is endless..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Test-driven development](https://en.wikipedia.org/wiki/Test-driven_development) aka TDD\n",
    "In short, the basic idea of TDD is to write tests before writing the actual implementation. Maybe the most significant benefit of the approach is that the developer focuses on writing tests which match with what the program should do. Whereas if the tests are written after the actual implementation, there is a high risk for rushing tests which just show green light for the already written logic.\n",
    "\n",
    "Tests are first class citizens in modern, agile software development, which is why it's important to start thinking TDD early during your Python learning path. \n",
    "\n",
    "The workflow of TDD can be summarized as follows:\n",
    "1. Add a test case(s) for the change / feature / bug fix you are going to implement\n",
    "2. Run all tests and check that the new one fails\n",
    "3. Implement required changes\n",
    "4. Run tests and verify that all pass\n",
    "5. Refactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running pytest inside notebooks\n",
    "These are the steps required to run pytest inside Jupyter cells. You can copy the content of this cell to the top of your notebook which contains tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c:\\Program' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'c:\\Program' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Let's make sure pytest and ipytest packages are installed\n",
    "# ipytest is required for running pytest inside Jupyter notebooks\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install pytest\n",
    "!{sys.executable} -m pip install ipytest\n",
    "\n",
    "# These are needed for running pytest inside Jupyter notebooks\n",
    "import ipytest\n",
    "\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are needed for running pytest inside Jupyter notebooks\n",
    "import ipytest\n",
    "\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pytest` test cases\n",
    "Let's consider we have a function called `sum_of_three_numbers` for which we want to write a test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_three_numbers(num1, num2, num3):\n",
    "    return num1 + num2 + num3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytest test cases are actually quite similar as you have already seen in the exercises. Most of the exercises are structured like pytest test cases by dividing each exercise into three cells:\n",
    "1. Setup the variables used in the test\n",
    "2. Your implementation\n",
    "3. Verify that your implementation does what is wanted by using assertions\n",
    "\n",
    "See the example test case below to see the similarities between the exercises and common structure of test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
      "============================================ FAILURES =============================================\n",
      "\u001b[31m\u001b[1m____________________________________ test_sum_of_three_numbers ____________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mtest_sum_of_three_numbers\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# 1. Setup the variables used in the test\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        num1 = \u001b[94m2\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        num2 = \u001b[94m3\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        num3 = \u001b[94m5\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# 2. Call the functionality you want to test\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        result = sum_of_three_numbers(num1, num2, num3)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# 3. Verify that the outcome is expected\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m result == \u001b[94m9\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert 10 == 9\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\Lisardo Iniesta\\AppData\\Local\\Temp\\ipykernel_18744\\915144.py\u001b[0m:11: AssertionError\n",
      "\u001b[36m\u001b[1m===================================== short test summary info =====================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m t_4fc94b05a1ef4d07a60500d15ef7eb57.py::\u001b[1mtest_sum_of_three_numbers\u001b[0m - assert 10 == 9\n",
      "\u001b[31m\u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 0.41s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_sum_of_three_numbers():\n",
    "    # 1. Setup the variables used in the test\n",
    "    num1 = 2\n",
    "    num2 = 3\n",
    "    num3 = 5\n",
    "    \n",
    "    # 2. Call the functionality you want to test\n",
    "    result = sum_of_three_numbers(num1, num2, num3)\n",
    "    \n",
    "    # 3. Verify that the outcome is expected\n",
    "    assert result == 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go ahead and change the line `assert result == 10` such that the assertion fails to see the output of a failed test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
